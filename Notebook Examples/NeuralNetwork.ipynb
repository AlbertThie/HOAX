{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-950236f055b8>, line 154)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-950236f055b8>\"\u001b[1;36m, line \u001b[1;32m154\u001b[0m\n\u001b[1;33m    self.hidden = torch.nn.ModuleList())\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, config, train_input,train_ouput,val_input,val_output,\n",
    "                 hiddenlayer_sizes=[50],hiddenlayer_number =[50], learning_rate=1e-3): \n",
    "       \n",
    "        self.dataset = NNDataset(train_input,train_output)\n",
    "        self.validationset = NNDataset(val_input,val_output)\n",
    "        self.dataloader = DataLoader(self.dataset, batch_size=256,shuffle= 'True')\n",
    "        \n",
    "        #self.dataset.output_shape()\n",
    "        self.epochs = config['config']['neural_network']['epochs']\n",
    "        self.epochsteps = config['config']['neural_network']['epoch_steps']\n",
    "\n",
    "        self.loggingfile = config['config']['neural_network']['logging_file']\n",
    "        self.printingfile = config['config']['neural_network']['ploting_file']\n",
    "        network = NeuralNet( len(train_input[0]), hiddenlayer_sizes, hiddenlayer_number, len(train_output[0]),  \n",
    "                              config['config']['neural_network']['activation'])\n",
    "        self.model = network.model\n",
    "        self.loss_fn = self.get_loss_function()\n",
    "        self.model.double()\n",
    "    # Use the optim package to define an Optimizer that will update the weights of\n",
    "    # the model for us. Here we will use Adam; the optim package contains many other\n",
    "    # optimization algoriths. The first argument to the Adam constructor tells the\n",
    "    # optimizer which Tensors it should update.\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # N is batch size; D_in is input dimension;\n",
    "        # H is hidden dimension; D_out is output dimension.\n",
    "        # create your dataset\n",
    "        # create your dataloade\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_interpolators(self, db, properties):\n",
    "        print(\"test\")\n",
    "\n",
    "    def save(self, filename):\n",
    "        torch.save(self.model, filename)\n",
    "\n",
    "    def load(self, filename):\n",
    "        self.model = torch.load(filename)\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "\n",
    "    def get_interpolators_from_file(self, filename, properties):\n",
    "        \"\"\"Properties contains a tuple of [energy,gradient] \"\"\"\n",
    "        return {prop_name: self.db[prop_name].shape[1:] for prop_name in properties}\n",
    "\n",
    "\n",
    "    def get(self, request):\n",
    "        \"\"\"Gives object with coordinates and desired properties\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _train(self):\n",
    "        for t in range(self.epochs):\n",
    "\n",
    "            for index, data in enumerate(self.dataloader,0):\n",
    "                local_batch, local_labels = data\n",
    "                #print(local_batch)\n",
    "                # Forward pass: compute predicted y by passing x to the model.\n",
    "                y_pred = self.model(local_batch)\n",
    "\n",
    "                # Compute and print loss.\n",
    "                #print(y_pred)\n",
    "                #print(local_labels)\n",
    "                loss = self.loss_fn(y_pred, local_labels)\n",
    "                #print(loss)\n",
    "\n",
    "                # Before the backward pass, use the optimizer object to zero all of the\n",
    "                # gradients for the variables it will update (which are the learnable\n",
    "                # weights of the model). This is because by default, gradients are\n",
    "                # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "                # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "                self.optimizer.zero_grad()\n",
    "                # Backward pass: compute gradient of the loss with respect to model\n",
    "                # parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Calling the step function on an Optimizer makes an update to its\n",
    "                # parameters\n",
    "                self.optimizer.step()\n",
    "                \n",
    "\n",
    "            if t % self.epochsteps == 0:\n",
    "                \n",
    "                lossprint = np.sqrt(self.validate_model(t)/len(self.validationset))\n",
    "                print(f\"{lossprint} {t} {self.hiddenlayer_sizes}\")\n",
    "                self.printingfile.append((self.hiddenlayer_sizes,t,lossprint))\n",
    "                with open('printoutNormGroundBGrid.txt', 'wb') as f:\n",
    "                    pickle.dump(self.printingfile,f)\n",
    "                file = open(self.loggingfile,\"a\")\n",
    "                file.write(f\"Loss = {lossprint} \\n Epochs = {self.epochs} \\n Hiddenlayers = {self.hiddenlayer_sizes} \\n Learningrate = {self.learning_rate} \\n Validation_percent = {self.validation_percent} \\n Batchsize = {self.N} \\n \\n\")\n",
    "                file.close()\n",
    "\n",
    "        print(\"Done Training\")\n",
    "        return lossprint\n",
    "    def validate_model(self,n):\n",
    "        model_predictions = []\n",
    "        testpoint_positions = []\n",
    "        losssquared = 0\n",
    "        for local_batch, local_labels in self.validationset:\n",
    "                # Forward pass: compute predicted y by passing x to the model.\n",
    "                y_pred = self.model(torch.flatten(local_batch))\n",
    "                #print(y_pred)\n",
    "                model_predictions.append(y_pred.tolist())\n",
    "                # Compute and print loss\n",
    "                testpoint_positions.append(local_batch.tolist())\n",
    "                loss = self.loss_fn(y_pred, local_labels)\n",
    "                losssquared += loss.item()\n",
    "        #print(model_predictions)\n",
    "        if np.sqrt(losssquared /len(self.validationset))< 0.001 :\n",
    "            plt.plot(self.vdb['energy']-np.amin(self.vdb['energy']))\n",
    "            plt.plot(model_predictions)\n",
    "            \n",
    "            plt.savefig(f\"graph{n}{self.hiddenlayer_sizes}sixlayer.png\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        return losssquared\n",
    "    \n",
    "    def get_loss_function(self):\n",
    "        if config['config']['Neural_Network']['loss_function'] == 'MSE':\n",
    "            return (torch.nn.MSELoss())\n",
    "\n",
    "class NNDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Molecule Data set\"\"\"\n",
    "\n",
    "    def __init__(self, coordinates, energyCurves):\n",
    "        self.coordinates = coordinates\n",
    "        self.energyCurves = energyCurves\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        coordinate = self.coordinates[index]\n",
    "        curve = self.energyCurves[index]\n",
    "\n",
    "        return coordinate, curve\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coordinates)\n",
    "        \n",
    "    def input_shape(self):\n",
    "        return list(self.coordinates[0].size())[0] *3\n",
    "    def output_shape(self):\n",
    "        return list(self.energyCurves[0].size())[0]\n",
    "\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, inputsize, hiddensize, hiddennumber, outputsize, normalizer=\"tanh\"):\n",
    "        self.hidden = torch.nn.ModuleList())\n",
    "        if normalizer == \"tanh\":\n",
    "            self.hidden.append(torch.nn.Linear(inputsize, hiddensize))\n",
    "            self.hidden.append(torch.nn.Tanh())\n",
    "            for k in range(hiddennumber):\n",
    "                self.hidden.append(torch.nn.Linear(hiddensize, hiddensize))\n",
    "                self.hidden.append(torch.nn.Tanh())\n",
    "            self.hidden.append(torch.nn.Linear(hiddensize,outputsize))\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterEnv",
   "language": "python",
   "name": "jupyterenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
