{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='configSA.json' mode='r' encoding='UTF-8'>\n",
      "{'config': {'debug': 'on', 'database': {'file': 'db.dat', 'properties': ['energy', 'gradient'], 'crdmode': 'cartesian', 'timestamp': '2021-04-23T18:25:43.511Z', 'mode': 'ab-initio', 'ab-initio': {'exe': 'QChem.exe', 'chg': 0, 'mult': 1, 'exchange': 'pbe0', 'basis': 'cc-pvdz', 'max_scf_cycles': 500, 'xc_grid': '000075000302', 'mem_static': 4000, 'mem_total': 16000, 'sym_ignore': True, 'set_iter': 50, 'input_bohr': True}}, 'neural_network': {'epochs': 1000, 'epoch_step': 50, 'logging_file': 'logfile.txt', 'plotting_file': 'plottingfile.txt', 'optimizer': 'adam', 'activation': 'tanh', 'loss_function': 'MSE', 'model_filename': 'Network.pt'}, 'simulated_annealing': {'hiddenlayer_size': [10, 200, 10], 'validation_ratio': 0.1, 'hiddenlayer_number': [1, 20, 1], 'learning_rates': [1, 0.1, 0.01, 0.001, 0.0001], 'batch_size': [32, 64, 128, 256, 512], 'iterations': 2000, 'temperature': 0.01}}}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import NeuralNetwork\n",
    "from SimulatedAnnealing import SimulatedAnnealing\n",
    "\n",
    "import math \n",
    "with open('configSA.json') as f:\n",
    "  print(f)\n",
    "  config = json.loads(f.read())\n",
    "import random\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lowest_error, best_network = math.inf, None\n",
    "sizebounds = config['config']['simulated_annealing']['hiddenlayer_size']\n",
    "layerbounds = config['config']['simulated_annealing']['hiddenlayer_number']\n",
    "learningbounds = config['config']['simulated_annealing']['learning_rates']\n",
    "\n",
    "\n",
    "print(random.randint(sizebounds[0],sizebounds[1]))\n",
    "print(random.choice(learningbounds))\n",
    "\n",
    "#for n in range(self.config['config']['simulated_annealing']['iterations']) :\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.77941757 2.76440917 4.84697076]\n",
      " [2.76698152 2.76900611 4.83948085]\n",
      " [2.75691651 2.77593716 4.83429377]\n",
      " [2.74938863 2.78508657 4.83143719]\n",
      " [2.74453164 2.79630852 4.83089482]\n",
      " [2.74244372 2.80942972 4.83260669]\n",
      " [2.7431851  2.82425238 4.83647096]\n",
      " [2.74677709 2.8405571  4.84234703]\n",
      " [2.75320254 2.85810566 4.8500602 ]\n",
      " [2.76240746 2.87664359 4.85940741]\n",
      " [2.77430386 2.89590254 4.87016427]]\n",
      "[[1.30026000e-05 1.38476884e-01 1.58162384e-01]\n",
      " [0.00000000e+00 1.39150584e-01 1.58955644e-01]\n",
      " [2.89870001e-05 1.39480344e-01 1.59147334e-01]\n",
      " [8.40001001e-05 1.39443554e-01 1.58714964e-01]\n",
      " [1.63652300e-04 1.39037264e-01 1.57668304e-01]\n",
      " [2.81846500e-04 1.38279024e-01 1.56049534e-01]\n",
      " [4.67269800e-04 1.37206234e-01 1.53931434e-01]\n",
      " [7.61541000e-04 1.35874014e-01 1.51413464e-01]\n",
      " [1.21603860e-03 1.34351604e-01 1.48616114e-01]\n",
      " [1.88761530e-03 1.32717424e-01 1.45673914e-01]\n",
      " [2.83360780e-03 1.31053354e-01 1.42727624e-01]]\n"
     ]
    }
   ],
   "source": [
    "database = 'db.dat'\n",
    "data = Dataset(database, mode='r')\n",
    "if config['config'][\"database\"][\"crdmode\"] == \"cartesian\":\n",
    "    dbset = np.copy(data['crd'])\n",
    "    coordinatesout = []\n",
    "    for j,i in enumerate(dbset):\n",
    "        if j == 0:\n",
    "            coordinatesout = [pdist(i)]\n",
    "        else:\n",
    "            coordinatesout = np.concatenate((coordinatesout,[pdist(i)]))\n",
    "            \n",
    "energyout =np.copy(data['energy'])-np.amin(data['energy'])     \n",
    "print(coordinatesout)\n",
    "print(energyout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.63652300e-04 1.39037264e-01 1.57668304e-01]\n",
      " [1.30026000e-05 1.38476884e-01 1.58162384e-01]\n",
      " [1.21603860e-03 1.34351604e-01 1.48616114e-01]\n",
      " [2.83360780e-03 1.31053354e-01 1.42727624e-01]\n",
      " [7.61541000e-04 1.35874014e-01 1.51413464e-01]\n",
      " [8.40001001e-05 1.39443554e-01 1.58714964e-01]\n",
      " [4.67269800e-04 1.37206234e-01 1.53931434e-01]\n",
      " [1.88761530e-03 1.32717424e-01 1.45673914e-01]\n",
      " [2.89870001e-05 1.39480344e-01 1.59147334e-01]] [[0.         0.13915058 0.15895564]\n",
      " [0.00028185 0.13827902 0.15604953]]\n",
      "[[2.74453164 2.79630852 4.83089482]\n",
      " [2.77941757 2.76440917 4.84697076]\n",
      " [2.75320254 2.85810566 4.8500602 ]\n",
      " [2.77430386 2.89590254 4.87016427]\n",
      " [2.74677709 2.8405571  4.84234703]\n",
      " [2.74938863 2.78508657 4.83143719]\n",
      " [2.7431851  2.82425238 4.83647096]\n",
      " [2.76240746 2.87664359 4.85940741]\n",
      " [2.75691651 2.77593716 4.83429377]] [[2.76698152 2.76900611 4.83948085]\n",
      " [2.74244372 2.80942972 4.83260669]]\n"
     ]
    }
   ],
   "source": [
    "coordinates, val_coordinates, output, val_output = train_test_split(coordinatesout, energyout , test_size=config['config']['simulated_annealing']['validation_ratio'])\n",
    "\n",
    "print(output,val_output)\n",
    "print(coordinates, val_coordinates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1200039369701452 0 50 18 0.001\n",
      "0.006710514426376788 50 50 18 0.001\n",
      "0.0033881246484374614 100 50 18 0.001\n",
      "0.0031234068999201766 150 50 18 0.001\n",
      "0.0031288516608743546 200 50 18 0.001\n",
      "0.0031283255746651925 250 50 18 0.001\n",
      "0.003128384093671232 300 50 18 0.001\n",
      "0.003128377366610394 350 50 18 0.001\n",
      "0.00312836551155091 400 50 18 0.001\n",
      "0.00312835202415786 450 50 18 0.001\n",
      "0.003128337068112501 500 50 18 0.001\n",
      "0.003128320320750205 550 50 18 0.001\n",
      "0.0031283013283605033 600 50 18 0.001\n",
      "0.003128279471684354 650 50 18 0.001\n",
      "0.003128253891239245 700 50 18 0.001\n",
      "0.0031282233724843483 750 50 18 0.001\n",
      "0.0031281861556328653 800 50 18 0.001\n",
      "0.0031281396081894097 850 50 18 0.001\n",
      "0.0031280796322718366 900 50 18 0.001\n",
      "0.0031279995238403776 950 50 18 0.001\n",
      "Done Training\n",
      "4\n",
      "16\n",
      "4\n",
      "0\n",
      "0.1959374617438448 0 50 17 0.0001\n",
      "0.08274007938723595 50 50 17 0.0001\n",
      "0.007295485316775885 100 50 17 0.0001\n",
      "0.003150030692430287 150 50 17 0.0001\n",
      "0.0031094204132238934 200 50 17 0.0001\n",
      "0.0031276248353072538 250 50 17 0.0001\n",
      "0.0031264014810484316 300 50 17 0.0001\n",
      "0.0031263323983190343 350 50 17 0.0001\n",
      "0.003126163794764436 400 50 17 0.0001\n",
      "0.0031259780889834605 450 50 17 0.0001\n",
      "0.003125778721388938 500 50 17 0.0001\n",
      "0.003125564991007553 550 50 17 0.0001\n",
      "0.003125336364577576 600 50 17 0.0001\n",
      "0.003125092132040397 650 50 17 0.0001\n",
      "0.003124831371960499 700 50 17 0.0001\n",
      "0.0031245529292207564 750 50 17 0.0001\n",
      "0.003124255383919396 800 50 17 0.0001\n",
      "0.0031239370101630447 850 50 17 0.0001\n",
      "0.003123595722826526 900 50 17 0.0001\n",
      "0.0031232290092432407 950 50 17 0.0001\n",
      "Done Training\n",
      "new error found 0.0031094204132238934 \n",
      "error is: 0.0031094204132238934  lowest error  )0.0031234068999201766\n",
      "1.0013996272348487\n",
      "5\n",
      "17\n",
      "3\n",
      "0\n",
      "0.009809509442308855 0 60 18 0.001\n",
      "0.003714508558773976 50 60 18 0.001\n",
      "0.0030228029963965783 100 60 18 0.001\n",
      "0.003121662040070587 150 60 18 0.001\n",
      "0.003128535310583815 200 60 18 0.001\n",
      "0.003128254405678614 250 60 18 0.001\n",
      "0.003128234046359919 300 60 18 0.001\n",
      "0.0031281507362620723 350 60 18 0.001\n",
      "0.0031280094108595098 400 60 18 0.001\n",
      "0.003127716959587777 450 60 18 0.001\n",
      "0.0031268731866596323 500 60 18 0.001\n",
      "0.0031207657232390734 550 60 18 0.001\n",
      "0.0033482739215915064 600 60 18 0.001\n",
      "0.0030836014156578728 650 60 18 0.001\n",
      "0.0031269291311562283 700 60 18 0.001\n",
      "0.0031283619411350445 750 60 18 0.001\n",
      "0.003128105193171527 800 60 18 0.001\n",
      "0.0031279714184976617 850 60 18 0.001\n",
      "0.0031277917386719947 900 60 18 0.001\n",
      "0.0031274802547009454 950 60 18 0.001\n",
      "Done Training\n",
      "new error found 0.0030228029963965783 \n",
      "error is: 0.0030228029963965783  lowest error  )0.0031094204132238934\n",
      "1.0174744051408102\n",
      "4\n",
      "18\n",
      "4\n",
      "0\n",
      "0.20100672897457117 0 50 19 0.0001\n",
      "0.049322426611065 50 50 19 0.0001\n",
      "0.003878890846811785 100 50 19 0.0001\n",
      "0.003110858419040166 150 50 19 0.0001\n",
      "0.003134003071355157 200 50 19 0.0001\n",
      "0.003126932642485024 250 50 19 0.0001\n",
      "0.00312640044248441 300 50 19 0.0001\n",
      "0.0031262290168657786 350 50 19 0.0001\n",
      "0.003126102951781664 400 50 19 0.0001\n",
      "0.0031259714177032543 450 50 19 0.0001\n",
      "0.003125830055915413 500 50 19 0.0001\n",
      "0.003125678128672781 550 50 19 0.0001\n",
      "0.0031255149160834086 600 50 19 0.0001\n",
      "0.003125339516969254 650 50 19 0.0001\n",
      "0.003125150809782777 700 50 19 0.0001\n",
      "0.0031249474191154905 750 50 19 0.0001\n",
      "0.0031247276711464326 800 50 19 0.0001\n",
      "0.003124489534840472 850 50 19 0.0001\n",
      "0.0031242305451182934 900 50 19 0.0001\n",
      "0.0031239477023372497 950 50 19 0.0001\n",
      "Done Training\n",
      "new error found 0.003110858419040166 \n",
      "error is: 0.003110858419040166  lowest error  )0.0030228029963965783\n",
      "0.9739292400547536\n",
      "4\n",
      "17\n",
      "4\n",
      "1\n",
      "0.06351758999355664 0 50 18 0.0001\n",
      "0.004270245048018298 50 50 18 0.0001\n",
      "0.00305153660896836 100 50 18 0.0001\n",
      "0.0031217348009704724 150 50 18 0.0001\n",
      "0.0031280316000803585 200 50 18 0.0001\n",
      "0.0031284253638490457 250 50 18 0.0001\n",
      "0.003128396614673751 300 50 18 0.0001\n",
      "0.003128384402323182 350 50 18 0.0001\n",
      "0.003128373655404939 400 50 18 0.0001\n",
      "0.003128362109199221 450 50 18 0.0001\n",
      "0.003128350032565981 500 50 18 0.0001\n",
      "0.0031283374058410146 550 50 18 0.0001\n",
      "0.0031283242209515635 600 50 18 0.0001\n",
      "0.003128310459259056 650 50 18 0.0001\n",
      "0.00312829609316749 700 50 18 0.0001\n",
      "0.003128281085816616 750 50 18 0.0001\n",
      "0.0031282653906055994 800 50 18 0.0001\n",
      "0.0031282489504296696 850 50 18 0.0001\n",
      "0.0031282316966184977 900 50 18 0.0001\n",
      "0.0031282135475410506 950 50 18 0.0001\n",
      "Done Training\n",
      "new error found 0.00305153660896836 \n",
      "error is: 0.00305153660896836  lowest error  )0.003110858419040166\n",
      "1.0240124902254542\n",
      "3\n",
      "17\n",
      "4\n",
      "0\n",
      "0.13641504297349694 0 40 18 0.0001\n",
      "0.025298305971509914 50 40 18 0.0001\n",
      "0.0029585276147423927 100 40 18 0.0001\n",
      "0.0030142160286481434 150 40 18 0.0001\n",
      "0.003122928162322191 200 40 18 0.0001\n",
      "0.003128109193734361 250 40 18 0.0001\n",
      "0.003128199229656217 300 40 18 0.0001\n",
      "0.0031281847528992902 350 40 18 0.0001\n",
      "0.0031281563452741985 400 40 18 0.0001\n",
      "0.0031281248560902455 450 40 18 0.0001\n",
      "0.0031280913282362073 500 40 18 0.0001\n",
      "0.0031280559722129 550 40 18 0.0001\n",
      "0.0031280188036211 600 40 18 0.0001\n",
      "0.0031279798042760537 650 40 18 0.0001\n",
      "0.003127938938320437 700 40 18 0.0001\n",
      "0.003127896152511475 750 40 18 0.0001\n",
      "0.0031278513759332213 800 40 18 0.0001\n",
      "0.0031278045193380466 850 40 18 0.0001\n",
      "0.0031277554740481712 900 40 18 0.0001\n",
      "0.003127704110423482 950 40 18 0.0001\n",
      "Done Training\n",
      "new error found 0.0029585276147423927 \n",
      "error is: 0.0029585276147423927  lowest error  )0.00305153660896836\n",
      "1.0476027902460503\n",
      "2\n",
      "17\n",
      "3\n",
      "0\n",
      "0.1595632484579769 0 30 18 0.001\n",
      "0.007505848196833522 50 30 18 0.001\n",
      "0.0030904759609938193 100 30 18 0.001\n",
      "0.0031496673727327636 150 30 18 0.001\n",
      "0.0031301047663491325 200 30 18 0.001\n",
      "0.003128458378661283 250 30 18 0.001\n",
      "0.003128399356103378 300 30 18 0.001\n",
      "0.0031284072298232483 350 30 18 0.001\n",
      "0.003128404531092184 400 30 18 0.001\n",
      "0.0031284024582011113 450 30 18 0.001\n",
      "0.003128400265894169 500 30 18 0.001\n",
      "0.0031283979831030835 550 30 18 0.001\n",
      "0.0031283956162019475 600 30 18 0.001\n",
      "0.0031283931675888184 650 30 18 0.001\n",
      "0.003128390638149672 700 30 18 0.001\n",
      "0.0031283880273287263 750 30 18 0.001\n",
      "0.003128385333148908 800 30 18 0.001\n",
      "0.003128382552198377 850 30 18 0.001\n",
      "0.003128379679586985 900 30 18 0.001\n",
      "0.0031283767088742948 950 30 18 0.001\n",
      "Done Training\n",
      "new error found 0.0030904759609938193 \n",
      "error is: 0.0030904759609938193  lowest error  )0.0029585276147423927\n",
      "0.9238837677319743\n",
      "3\n",
      "16\n",
      "3\n",
      "1\n",
      "0.17366560232626507 0 40 17 0.001\n",
      "0.005838072505901249 50 40 17 0.001\n",
      "0.003200740477983073 100 40 17 0.001\n",
      "0.0031439603003597487 150 40 17 0.001\n",
      "0.0031272725999711404 200 40 17 0.001\n",
      "0.003128187884252146 250 40 17 0.001\n",
      "0.003128247794992912 300 40 17 0.001\n",
      "0.0031281319200990687 350 40 17 0.001\n",
      "0.0031279931674723033 400 40 17 0.001\n",
      "0.00312782030074897 450 40 17 0.001\n",
      "0.0031275961690154005 500 40 17 0.001\n",
      "0.0031272895455284255 550 40 17 0.001\n",
      "0.0031268404598912393 600 40 17 0.001\n",
      "0.00312612026745053 650 40 17 0.001\n",
      "0.0031248030581395906 700 40 17 0.001\n",
      "0.0031218119652783147 750 40 17 0.001\n",
      "0.003111121653139214 800 40 17 0.001\n",
      "0.0029891300057648114 850 40 17 0.001\n",
      "0.0008909108254290287 900 40 17 0.001\n",
      "0.0002119542495488924 950 40 17 0.001\n",
      "Done Training\n",
      "new error found 0.0002119542495488924 \n",
      "error is: 0.0002119542495488924  lowest error  )0.0030904759609938193\n",
      "7.500466345516824\n",
      "2\n",
      "17\n",
      "3\n",
      "1\n",
      "0.16568288972314393 0 30 18 0.001\n",
      "0.004204146236933183 50 30 18 0.001\n",
      "0.0031162937934914076 100 30 18 0.001\n",
      "0.003133854641573476 150 30 18 0.001\n",
      "0.0031265461422153944 200 30 18 0.001\n",
      "0.003128377264834269 250 30 18 0.001\n",
      "0.0031284289828155338 300 30 18 0.001\n",
      "0.003128421914392891 350 30 18 0.001\n",
      "0.003128420732613125 400 30 18 0.001\n",
      "0.0031284197298635957 450 30 18 0.001\n",
      "0.003128418624255061 500 30 18 0.001\n",
      "0.00312841748656934 550 30 18 0.001\n",
      "0.0031284163214412323 600 30 18 0.001\n",
      "0.0031284151314083294 650 30 18 0.001\n",
      "0.003128413918605605 700 30 18 0.001\n",
      "0.0031284126847342377 750 30 18 0.001\n",
      "0.0031284114310928014 800 30 18 0.001\n",
      "0.0031284101586086257 850 30 18 0.001\n",
      "0.0031284088678595495 900 30 18 0.001\n",
      "0.0031284075590893514 950 30 18 0.001\n",
      "Done Training\n",
      "new error found 0.0031162937934914076 \n",
      "error is: 0.0031162937934914076  lowest error  )0.0002119542495488924\n",
      "0.09793300709409249\n",
      "2\n",
      "15\n",
      "3\n",
      "0\n",
      "0.18336356484845578 0 30 16 0.001\n",
      "0.005023733058993633 50 30 16 0.001\n",
      "0.002848341611515765 100 30 16 0.001\n",
      "0.0031097854132995516 150 30 16 0.001\n",
      "0.003129534319058344 200 30 16 0.001\n",
      "0.0031285379713534163 250 30 16 0.001\n",
      "0.00312855272506185 300 30 16 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0031285363924175597 350 30 16 0.001\n",
      "0.0031285158043573213 400 30 16 0.001\n",
      "0.0031284947689585534 450 30 16 0.001\n",
      "0.0031284728894177436 500 30 16 0.001\n",
      "0.003128450149255072 550 30 16 0.001\n",
      "0.003128426558001326 600 30 16 0.001\n",
      "0.003128402102579299 650 30 16 0.001\n",
      "0.003128376741297972 700 30 16 0.001\n",
      "0.0031283504018845077 750 30 16 0.001\n",
      "0.00312832297856468 800 30 16 0.001\n",
      "0.003128294327782544 850 30 16 0.001\n",
      "0.003128264262215148 900 30 16 0.001\n",
      "0.0031282325425638865 950 30 16 0.001\n",
      "Done Training\n",
      "new error found 0.002848341611515765 \n",
      "error is: 0.002848341611515765  lowest error  )0.0002119542495488924\n",
      "0.09322413554229332\n",
      "4\n",
      "15\n",
      "3\n",
      "0\n",
      "0.18136683057435152 0 50 16 0.001\n",
      "0.008376646895623008 50 50 16 0.001\n",
      "0.003196188353045915 100 50 16 0.001\n",
      "0.0031036901307201475 150 50 16 0.001\n",
      "0.0031285763191250295 200 50 16 0.001\n",
      "0.0031285557714773172 250 50 16 0.001\n",
      "0.0031284169605468952 300 50 16 0.001\n",
      "0.0031283858734447805 350 50 16 0.001\n",
      "0.0031283604430963866 400 50 16 0.001\n",
      "0.0031283328977733493 450 50 16 0.001\n",
      "0.003128303427922368 500 50 16 0.001\n",
      "0.0031282719256363286 550 50 16 0.001\n",
      "0.0031282381706818725 600 50 16 0.001\n",
      "0.003128201855732212 650 50 16 0.001\n",
      "0.0031281625676970485 700 50 16 0.001\n",
      "0.003128119763042293 750 50 16 0.001\n",
      "0.003128072733218639 800 50 16 0.001\n",
      "0.0031280205555040824 850 50 16 0.001\n",
      "0.0031279620223486036 900 50 16 0.001\n",
      "0.0031278955381584257 950 50 16 0.001\n",
      "Done Training\n",
      "new error found 0.0031036901307201475 \n",
      "error is: 0.0031036901307201475  lowest error  )0.0002119542495488924\n",
      "0.05547982259545228\n",
      "2\n",
      "17\n",
      "2\n",
      "0\n",
      "0.042441570966986975 0 30 18 0.01\n",
      "0.0025073718541139284 50 30 18 0.01\n",
      "0.003215693059521935 100 30 18 0.01\n",
      "0.003117880225245673 150 30 18 0.01\n",
      "0.0036243628262732316 200 30 18 0.01\n",
      "0.003082123501474717 250 30 18 0.01\n",
      "0.0032811096391232746 300 30 18 0.01\n",
      "0.0031076379001348303 350 30 18 0.01\n",
      "0.0031258325738720157 400 30 18 0.01\n",
      "0.0031275714419279955 450 30 18 0.01\n",
      "0.00312629925394897 500 30 18 0.01\n",
      "0.005508785690108526 550 30 18 0.01\n",
      "0.0031724527937840455 600 30 18 0.01\n",
      "0.0031239348182600488 650 30 18 0.01\n",
      "0.0031282225333954055 700 30 18 0.01\n",
      "0.0031284287518753584 750 30 18 0.01\n",
      "0.0031284143084429365 800 30 18 0.01\n",
      "0.0031284128022849634 850 30 18 0.01\n",
      "0.0031284107112015 900 30 18 0.01\n",
      "0.0031284086467988008 950 30 18 0.01\n",
      "Done Training\n",
      "new error found 0.0025073718541139284 \n",
      "error is: 0.0025073718541139284  lowest error  )0.0002119542495488924\n",
      "0.0800615660206333\n",
      "4\n",
      "15\n",
      "2\n",
      "1\n",
      "0.12391093892009135 0 50 16 0.01\n",
      "0.004170459262637041 50 50 16 0.01\n",
      "0.0032079191631001923 100 50 16 0.01\n",
      "0.0031215339093534572 150 50 16 0.01\n",
      "0.0031284188766218324 200 50 16 0.01\n",
      "0.003128366205561657 250 50 16 0.01\n",
      "0.0031283528324897347 300 50 16 0.01\n",
      "0.0031283465412009223 350 50 16 0.01\n",
      "0.0031283420361323294 400 50 16 0.01\n",
      "0.0031283367318214036 450 50 16 0.01\n",
      "0.0031283303976508423 500 50 16 0.01\n",
      "0.003128322711743104 550 50 16 0.01\n",
      "0.003128313211740923 600 50 16 0.01\n",
      "0.0031283011504356236 650 50 16 0.01\n",
      "0.003128285206544578 700 50 16 0.01\n",
      "0.0031282627538478545 750 50 16 0.01\n",
      "0.003128228070269352 800 50 16 0.01\n",
      "0.0031281715547274635 850 50 16 0.01\n",
      "0.0031280921238800038 900 50 16 0.01\n",
      "0.003127977148997117 950 50 16 0.01\n",
      "Done Training\n",
      "new error found 0.0031215339093534572 \n",
      "error is: 0.0031215339093534572  lowest error  )0.0002119542495488924\n",
      "0.030455289413053817\n",
      "2\n",
      "16\n",
      "2\n",
      "0\n",
      "0.11483069281305304 0 30 17 0.01\n",
      "0.0028977013068301706 50 30 17 0.01\n",
      "0.0032108872297712675 100 30 17 0.01\n",
      "0.0031247916262854723 150 30 17 0.01\n",
      "0.003128632720799706 200 30 17 0.01\n",
      "0.00312834510215832 250 30 17 0.01\n",
      "0.0031283855028322416 300 30 17 0.01\n",
      "0.003128381415998942 350 30 17 0.01\n",
      "0.0031283785166494596 400 30 17 0.01\n",
      "0.0031283751552529096 450 30 17 0.01\n",
      "0.0031283710126932076 500 30 17 0.01\n",
      "0.003128466718314288 550 30 17 0.01\n",
      "0.004069281196442804 600 30 17 0.01\n",
      "0.003048688285457154 650 30 17 0.01\n",
      "0.0031273562400303333 700 30 17 0.01\n",
      "0.00312808679928531 750 30 17 0.01\n",
      "0.0031283842880185735 800 30 17 0.01\n",
      "0.003128367523485882 850 30 17 0.01\n",
      "0.0031283635807521164 900 30 17 0.01\n",
      "0.0031283545688386987 950 30 17 0.01\n",
      "Done Training\n",
      "new error found 0.0028977013068301706 \n",
      "error is: 0.0028977013068301706  lowest error  )0.0002119542495488924\n",
      "0.030456033058065258\n",
      "4\n",
      "15\n",
      "2\n",
      "2\n",
      "0.1645124493230669 0 50 16 0.01\n",
      "0.001811259874519424 50 50 16 0.01\n",
      "0.0032017512500431794 100 50 16 0.01\n",
      "0.0031297361600885125 150 50 16 0.01\n",
      "0.0031281638699663643 200 50 16 0.01\n",
      "0.0031282791320962977 250 50 16 0.01\n",
      "0.0031282597943731462 300 50 16 0.01\n",
      "0.0031281936007735702 350 50 16 0.01\n",
      "0.003128108880551416 400 50 16 0.01\n",
      "0.003127952606876611 450 50 16 0.01\n",
      "0.0021460873595134417 500 50 16 0.01\n",
      "0.003051615531800965 550 50 16 0.01\n",
      "0.0031250466315383653 600 50 16 0.01\n",
      "0.003127890391616435 650 50 16 0.01\n",
      "0.00312814168410419 700 50 16 0.01\n",
      "0.003128080947961702 750 50 16 0.01\n",
      "0.0031279504124141974 800 50 16 0.01\n",
      "0.003127725450675028 850 50 16 0.01\n",
      "0.003127282035300113 900 50 16 0.01\n",
      "0.0031261653783979174 950 50 16 0.01\n",
      "Done Training\n",
      "new error found 0.001811259874519424 \n",
      "error is: 0.001811259874519424  lowest error  )0.0002119542495488924\n",
      "0.1065620456766044\n",
      "4\n",
      "17\n",
      "2\n",
      "0\n",
      "0.04708883948910618 0 50 18 0.01\n",
      "0.0024954522174928896 50 50 18 0.01\n",
      "0.003381775567599223 100 50 18 0.01\n",
      "0.0031349355863836592 150 50 18 0.01\n",
      "0.003129780463465546 200 50 18 0.01\n",
      "0.003128356655169912 250 50 18 0.01\n",
      "0.003128395283500363 300 50 18 0.01\n",
      "0.0031283894604444682 350 50 18 0.01\n",
      "0.003128388974238982 400 50 18 0.01\n",
      "0.0031283887291900033 450 50 18 0.01\n",
      "0.003128388440078555 500 50 18 0.01\n",
      "0.003128392037377013 550 50 18 0.01\n",
      "0.25590611138211306 600 50 18 0.01\n",
      "0.004793706229470319 650 50 18 0.01\n",
      "0.0038595568858620665 700 50 18 0.01\n",
      "0.0030662277309342887 750 50 18 0.01\n",
      "0.0031246575508833197 800 50 18 0.01\n",
      "0.0031287880823201086 850 50 18 0.01\n",
      "0.003128365406590135 900 50 18 0.01\n",
      "0.003128394204659527 950 50 18 0.01\n",
      "Done Training\n",
      "new error found 0.0024954522174928896 \n",
      "error is: 0.0024954522174928896  lowest error  )0.0002119542495488924\n",
      "0.03254124387423017\n",
      "2\n",
      "16\n",
      "4\n",
      "1\n",
      "0.04812605416528298 0 30 17 0.0001\n",
      "0.0037421039015806986 50 30 17 0.0001\n",
      "0.0030691330654741824 100 30 17 0.0001\n",
      "0.0031223170309792143 150 30 17 0.0001\n",
      "0.0031278754703348713 200 30 17 0.0001\n",
      "0.0031283772275181626 250 30 17 0.0001\n",
      "0.003128378960017972 300 30 17 0.0001\n",
      "0.003128372762896363 350 30 17 0.0001\n",
      "0.0031283684003503886 400 30 17 0.0001\n",
      "0.0031283637313742414 450 30 17 0.0001\n",
      "0.003128358822185869 500 30 17 0.0001\n",
      "0.0031283536787479966 550 30 17 0.0001\n",
      "0.003128348303069989 600 30 17 0.0001\n",
      "0.0031283426953199653 650 30 17 0.0001\n",
      "0.0031283368537449075 700 30 17 0.0001\n",
      "0.003128330774831351 750 30 17 0.0001\n",
      "0.0031283244533854234 800 30 17 0.0001\n",
      "0.0031283178825638174 850 30 17 0.0001\n",
      "0.0031283110538668233 900 30 17 0.0001\n",
      "0.003128303957098548 950 30 17 0.0001\n",
      "Done Training\n",
      "new error found 0.0030691330654741824 \n",
      "error is: 0.0030691330654741824  lowest error  )0.0002119542495488924\n",
      "0.010342578129073302\n",
      "2\n",
      "16\n",
      "3\n",
      "0\n",
      "0.22358285308806441 0 30 17 0.001\n",
      "0.007544002313715733 50 30 17 0.001\n",
      "0.003175169018657035 100 30 17 0.001\n",
      "0.0031326056312684465 150 30 17 0.001\n",
      "0.0031252429786039555 200 30 17 0.001\n",
      "0.0031284650943857596 250 30 17 0.001\n",
      "0.0031284324257605835 300 30 17 0.001\n",
      "0.0031284279532330264 350 30 17 0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8328c8b7ca6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'neural_network'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimulatedAnnealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/MachineLearningNew/MachineLearningScanner-2/SimulatedAnnealing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"old error {error} from library\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNewNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrialpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchlog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrialpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"new error found {error} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/MachineLearningNew/MachineLearningScanner-2/SimulatedAnnealing.py\u001b[0m in \u001b[0;36mgetNewNetwork\u001b[0;34m(self, positions)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                                     \u001b[0mhiddenlayer_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddenlayer_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                                     learning_rate=self.learningrate[positions[2]],batch_size=self.batchsize[positions[3]]) \n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/MachineLearningNew/MachineLearningScanner-2/NeuralNetwork.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m#print(local_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;31m# Forward pass: compute predicted y by passing x to the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;31m# Compute and print loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#if (any(i == 'simulated_annealing' for i in config['config'])):\n",
    "#    if (any(j == 'neural_network' for j in config['config'])):\n",
    "#        optimizer = SimulatedAnnealing(config,coordinates,  output,val_coordinates, val_output)\n",
    "#        optimizer.run()\n",
    "\n",
    "if (any(i == 'simulated_annealing' for i in config['config'])):\n",
    "    if (any(j == 'neural_network' for j in config['config'])):\n",
    "        optimizer = SimulatedAnnealing(config,coordinates,  output,val_coordinates, val_output)\n",
    "        optimizer.run()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Bijlagen",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
